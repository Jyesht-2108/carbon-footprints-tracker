# RAG Chatbot Capabilities Explained ğŸ¤–

## Your Questions Answered

### **Q1: How does the AI answer questions about the database?**
### **Q2: Does the RAG chatbot accept Excel, CSV, MD, and TXT files?**

---

## ğŸ§  **How the AI Knows Your Data**

The RAG (Retrieval-Augmented Generation) chatbot has **TWO sources of knowledge**:

### **1. Database Access** âœ…

**YES, the AI can access your database!**

The RAG service connects to **Supabase** (your database) and can query:
- âœ… Emissions data (`events_normalized` table)
- âœ… Hotspots (`hotspots` table)
- âœ… Recommendations (`recommendations` table)
- âœ… Alerts (`alerts` table)
- âœ… Predictions (`predictions` table)
- âœ… Data quality metrics (`data_quality` table)

**How it works**:
```typescript
// RAG service has database client
import { createClient } from '@supabase/supabase-js'

const db = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_KEY
)

// When you ask: "Which supplier has highest COâ‚‚?"
// AI queries database:
const { data } = await db
  .from('events_normalized')
  .select('supplier_id, co2_kg')
  .order('co2_kg', { ascending: false })
  .limit(1)

// AI responds: "Supplier X has 138.8 kg COâ‚‚"
```

### **2. Uploaded Documents** âœ…

The AI also learns from documents you upload:
- PDF reports
- Text files
- Markdown docs
- (Currently being expanded to support more formats)

---

## ğŸ“ **What File Types Does RAG Accept?**

### **Current Status** (As of now):

| File Type | Supported? | Status |
|-----------|------------|--------|
| **PDF** | âœ… YES | Fully working |
| **TXT** | âš ï¸ PARTIAL | Backend ready, needs frontend update |
| **MD** | âš ï¸ PARTIAL | Backend ready, needs frontend update |
| **CSV** | âŒ NO | Not for RAG (use Data Upload instead) |
| **XLSX** | âŒ NO | Not for RAG (use Data Upload instead) |
| **DOC/DOCX** | âš ï¸ PARTIAL | Backend ready, needs frontend update |

### **Why CSV/XLSX are NOT for RAG**:

CSV and Excel files contain **structured data** (rows and columns), not text documents. They should go to the **Data Upload page** for processing, not the RAG chatbot.

**Correct usage**:
- âœ… CSV/XLSX â†’ Data Upload page â†’ Database â†’ Dashboard
- âœ… PDF/TXT/MD â†’ AI Assistant â†’ RAG knowledge base â†’ Chat answers

---

## ğŸ”„ **How the AI Answers Your Questions**

### **Example 1: "Why are my emissions high today?"**

**Step 1**: AI receives your question

**Step 2**: AI queries database:
```sql
SELECT supplier_id, co2_kg, timestamp
FROM events_normalized
WHERE DATE(timestamp) = CURRENT_DATE
ORDER BY co2_kg DESC
```

**Step 3**: AI analyzes results:
- Finds: Supplier X has 138.8 kg COâ‚‚ (45% above baseline)
- Finds: Heavy_Load_Supplier has 120.2 kg COâ‚‚

**Step 4**: AI searches uploaded documents:
- Checks if you uploaded any carbon policies
- Checks for best practices documents

**Step 5**: AI generates response:
```
"Your emissions are high today primarily due to:

1. Supplier X (138.8 kg COâ‚‚) - 45% above baseline
   - Likely due to increased load factor
   - Suboptimal routing detected

2. Heavy_Load_Supplier (120.2 kg COâ‚‚) - 13% above baseline
   - Heavy loads with diesel fleet
   - No route optimization

Recommendations:
- Implement route optimization for Supplier X
- Consider load consolidation
- Evaluate electric vehicle options

[Based on your database data from today]"
```

---

### **Example 2: "Which supplier has the highest COâ‚‚?"**

**AI Process**:
```typescript
// 1. Query database
const result = await db
  .from('events_normalized')
  .select('supplier_id, SUM(co2_kg) as total')
  .group('supplier_id')
  .order('total', { ascending: false })
  .limit(1)

// 2. Get additional context
const hotspots = await db
  .from('hotspots')
  .select('*')
  .eq('entity', result.supplier_id)

// 3. Generate response
return `Hotspot_CRITICAL has the highest COâ‚‚ emissions at 138.8 kg, 
which is 45.1% above their baseline. This is flagged as a critical 
hotspot requiring immediate attention.`
```

---

### **Example 3: "How can I reduce emissions by 20%?"**

**AI Process**:
```typescript
// 1. Calculate current total
const current = await db
  .from('events_normalized')
  .select('SUM(co2_kg)')

// 2. Search uploaded documents for strategies
const strategies = await vectorSearch("carbon reduction strategies")

// 3. Get AI recommendations from database
const recommendations = await db
  .from('recommendations')
  .select('*')
  .eq('status', 'pending')

// 4. Generate personalized response
return `To reduce emissions by 20% (91 kg COâ‚‚):

Based on your data and uploaded policies:

1. Electric Vehicles (60% reduction potential)
   - Convert 33% of fleet to EVs
   - Estimated savings: 91 kg COâ‚‚
   - Cost: $15,000 | ROI: 8 months

2. Route Optimization (15% reduction potential)
   - Implement AI routing software
   - Estimated savings: 68 kg COâ‚‚
   - Cost: $5,000 | ROI: 4 months

3. Load Consolidation (20% reduction potential)
   - Combine shipments
   - Estimated savings: 91 kg COâ‚‚
   - Cost: $2,000 | ROI: 2 months

[Based on your current emissions of 455.5 kg COâ‚‚]`
```

---

## ğŸ¯ **What the AI Can Do**

### **Database Queries** âœ…:
- "What's my total COâ‚‚ today?"
- "Which supplier is worst?"
- "Show me all critical hotspots"
- "What are my pending recommendations?"
- "How many alerts do I have?"
- "What's my data quality score?"

### **Trend Analysis** âœ…:
- "Are emissions increasing or decreasing?"
- "Compare this week to last week"
- "What's the forecast for next week?"
- "Which day had highest emissions?"

### **Recommendations** âœ…:
- "How can I reduce emissions?"
- "What should I do about Supplier X?"
- "Give me cost-effective solutions"
- "What's the ROI on electric vehicles?"

### **Document-Based** âœ…:
- "What does our carbon policy say?"
- "Summarize the uploaded report"
- "What are industry best practices?"
- "Explain the guidelines in the PDF"

---

## ğŸ”§ **Technical Architecture**

### **RAG Service Components**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         RAG Chatbot Service             â”‚
â”‚         (Port 4000)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  1. Database Client (Supabase)          â”‚
â”‚     - Query emissions data              â”‚
â”‚     - Get hotspots, recommendations     â”‚
â”‚     - Access all tables                 â”‚
â”‚                                         â”‚
â”‚  2. Vector Database (Qdrant)            â”‚
â”‚     - Store document embeddings         â”‚
â”‚     - Semantic search                   â”‚
â”‚     - Find relevant context             â”‚
â”‚                                         â”‚
â”‚  3. LLM (OpenAI/Ollama)                 â”‚
â”‚     - Generate responses                â”‚
â”‚     - Combine database + documents      â”‚
â”‚     - Natural language understanding    â”‚
â”‚                                         â”‚
â”‚  4. Document Processing                 â”‚
â”‚     - PDF extraction âœ…                 â”‚
â”‚     - Text chunking                     â”‚
â”‚     - Embedding generation              â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **When You Ask a Question**:

```
User Question
     â†“
1. Parse intent
     â†“
2. Query database (if needed)
     â†“
3. Search uploaded docs (if relevant)
     â†“
4. Combine context
     â†“
5. Generate response with LLM
     â†“
6. Return answer
```

---

## ğŸ“ **File Type Support Details**

### **Currently Supported** âœ…:

**PDF Files**:
```typescript
// Full pipeline working:
1. Upload PDF
2. Extract text from all pages
3. Chunk into smaller pieces
4. Generate embeddings
5. Store in vector database
6. Search when answering questions
```

### **Needs Implementation** âš ï¸:

**TXT, MD, DOC Files**:
```typescript
// Backend is ready, just needs:
1. Text extraction (simpler than PDF)
2. Same chunking/embedding pipeline
3. Frontend already allows these formats!
```

**CSV/XLSX Files**:
```typescript
// Should NOT go to RAG because:
- They're structured data, not documents
- Should go to Data Upload page instead
- Get processed into database
- Then AI can query the database
```

---

## ğŸ¯ **Best Practices**

### **For Questions**:
âœ… **DO**: "Which supplier has highest COâ‚‚?"
âœ… **DO**: "How can I reduce emissions by 20%?"
âœ… **DO**: "Explain the forecast for next week"
âœ… **DO**: "What does our policy say about EVs?"

âŒ **DON'T**: Upload CSV to chat (use Data Upload page)
âŒ **DON'T**: Ask about data that hasn't been uploaded
âŒ **DON'T**: Expect real-time data (database updates every 30 min)

### **For Documents**:
âœ… **DO**: Upload PDF reports, policies, guidelines
âœ… **DO**: Upload text files with best practices
âœ… **DO**: Upload markdown documentation
âœ… **DO**: Ask questions about uploaded content

âŒ **DON'T**: Upload CSV/XLSX (wrong place)
âŒ **DON'T**: Upload images (not supported yet)
âŒ **DON'T**: Upload very large files (>10MB)

---

## ğŸš€ **Summary**

### **Q1: Does AI know the database?**
**YES!** âœ… The AI has full access to your Supabase database and can query all emissions data, hotspots, recommendations, and more.

### **Q2: What files does RAG accept?**
**Currently**: PDF âœ…  
**Soon**: TXT, MD, DOC âš ï¸  
**Never**: CSV, XLSX âŒ (use Data Upload page instead)

### **How AI Answers**:
1. Queries database for real data
2. Searches uploaded documents
3. Combines both sources
4. Generates intelligent response
5. Provides actionable insights

**The AI is smart because it has BOTH your data AND your documents!** ğŸ§ âœ¨
